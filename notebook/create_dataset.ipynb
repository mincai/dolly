{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb577b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bo_ling/python39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(\"...\"))\n",
    "sys.path.append(os.path.dirname(SCRIPT_DIR))\n",
    "from training.generate import (generate_response, load_model_tokenizer_for_generate, \n",
    "                               get_special_token_id, get_special_token_id)\n",
    "from training.consts import END_KEY, PROMPT_FORMAT, RESPONSE_KEY_NL\n",
    "from training.trainer import PROMPT_FORMAT, create_data_set_from_json_list\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "abeaf94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /home/prodadmin/.cache/huggingface/datasets/generator/default-71d75ecb741b2dcb/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/prodadmin/.cache/huggingface/datasets/generator/default-71d75ecb741b2dcb/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "file_to_instruction_map = {\n",
    "    \"/opt/home/bo_ling/dataset/michelangelo_so_long.jsonl\": \"Please answer the following MA helpdesk questions:\",\n",
    "    \"/opt/home/bo_ling/dataset/docstrans.jsonl\": \"Please finish the following doc translation tasks:\",\n",
    "    \"/opt/home/bo_ling/dataset/eats_goldenset.jsonl\": \"Please answer Uber eats products relation questions:\"\n",
    "}\n",
    "json_file = \"/opt/home/bo_ling/dataset/eats_goldenset.jsonl\"\n",
    "dataset_file = json_file.replace(\".jsonl\", \".hf\")\n",
    "dataset = create_data_set_from_json_list(json_file,\n",
    "                                         file_to_instruction_map=file_to_instruction_map) \n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "#dataset.save_to_disk(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644fe22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eef2151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text'],\n",
       "        num_rows: 157792\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text'],\n",
       "        num_rows: 17533\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = load_from_disk(\"/opt/home/bo_ling/dataset/eats_goldenset.hf\")\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4366efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /home/prodadmin/.cache/huggingface/datasets/generator/default-2da5259a7e982007/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/prodadmin/.cache/huggingface/datasets/generator/default-2da5259a7e982007/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "max_question_length=500\n",
    "max_answer_length=500\n",
    "with open(\"/opt/home/bo_ling/dataset/doc_transcript_pii_data.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "for d in json_data:\n",
    "    try:\n",
    "        instruction = d['instruction']+\":\"\n",
    "        input_text = d[\"input\"][:max_question_length]\n",
    "        output_text = \"\\n\" + d[\"output\"][:max_answer_length]\n",
    "        text = PROMPT_FORMAT.format(instruction=instruction,input_text=input_text,output_text=output_text)\n",
    "        data.append({\n",
    "                \"instruction\": instruction,\n",
    "                \"input\": input_text, \n",
    "                \"output\": output_text,\n",
    "                \"text\": text\n",
    "            })\n",
    "    except:\n",
    "        pass\n",
    "def gen():\n",
    "    for d in data:\n",
    "        yield d\n",
    "dataset = Dataset.from_generator(gen)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "#dataset.save_to_disk(\"/opt/home/bo_ling/dataset/doc_transcript_pii_data.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e884cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text'],\n",
       "        num_rows: 629797\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text'],\n",
       "        num_rows: 69978\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = load_from_disk(\"/opt/home/bo_ling/dataset/doc_transcript_pii_data.hf\")\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a174c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /home/prodadmin/.cache/huggingface/datasets/generator/default-7895c5e842d084b9/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 1796 examples [00:00, 17886.03 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 4053 examples [00:00, 20631.90 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 6371 examples [00:00, 21793.42 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 8686 examples [00:00, 22327.86 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 11000 examples [00:00, 22468.39 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 13360 examples [00:00, 22846.81 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 15714 examples [00:00, 23069.83 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 19192 examples [00:00, 23077.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 21533 examples [00:00, 23166.52 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 23885 examples [00:01, 23264.08 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 27380 examples [00:01, 23230.48 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 29736 examples [00:01, 23316.73 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 33173 examples [00:01, 23167.25 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 35542 examples [00:01, 23298.82 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 37882 examples [00:01, 23322.73 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 41400 examples [00:01, 23169.30 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 43775 examples [00:01, 23314.00 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 47274 examples [00:02, 23315.32 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 49643 examples [00:02, 23408.09 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 52000 examples [00:02, 23305.93 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 54378 examples [00:02, 23432.59 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 56736 examples [00:02, 23471.60 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 60223 examples [00:02, 23384.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 62580 examples [00:02, 23431.83 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 64971 examples [00:02, 23559.78 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 68418 examples [00:02, 23341.39 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 70796 examples [00:03, 23453.60 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 74249 examples [00:03, 23295.69 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 76604 examples [00:03, 23357.44 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 78976 examples [00:03, 23451.69 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 82485 examples [00:03, 23426.45 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 85944 examples [00:03, 23298.92 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 89410 examples [00:03, 23233.97 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 91770 examples [00:03, 23320.59 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 95240 examples [00:04, 23253.33 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 97599 examples [00:04, 23332.98 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 99963 examples [00:04, 23411.33 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 103419 examples [00:04, 23277.09 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 105772 examples [00:04, 23340.77 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 109126 examples [00:04, 22945.00 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 111484 examples [00:04, 23102.58 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 113848 examples [00:04, 23241.90 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 117363 examples [00:05, 23153.40 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 119703 examples [00:05, 23215.88 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 123196 examples [00:05, 23204.27 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 125565 examples [00:05, 23323.81 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 127921 examples [00:05, 23383.84 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 131398 examples [00:05, 23211.10 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 133759 examples [00:05, 23308.83 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 137273 examples [00:05, 23348.45 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 139655 examples [00:06, 23464.80 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 143197 examples [00:06, 23321.86 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 145564 examples [00:06, 23406.01 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 147922 examples [00:06, 23448.37 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 151399 examples [00:06, 23260.50 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 153761 examples [00:06, 23351.04 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 157197 examples [00:06, 23189.18 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 159538 examples [00:06, 23242.26 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 163000 examples [00:07, 23095.79 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 165351 examples [00:07, 23196.46 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 168810 examples [00:07, 23145.83 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                    \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/prodadmin/.cache/huggingface/datasets/generator/default-7895c5e842d084b9/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Saving the dataset (0/1 shards):   0%|                                                                                                                                                                                      | 0/152615 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  12%|███████████████████▌                                                                                                                                                  | 18000/152615 [00:00<00:00, 173411.10 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  26%|███████████████████████████████████████████▌                                                                                                                          | 40000/152615 [00:00<00:00, 195499.43 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  41%|███████████████████████████████████████████████████████████████████▍                                                                                                  | 62000/152615 [00:00<00:00, 204141.24 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  55%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 84000/152615 [00:00<00:00, 208141.68 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                  | 106000/152615 [00:00<00:00, 210292.04 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 128000/152615 [00:00<00:00, 212110.46 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 150000/152615 [00:00<00:00, 212473.75 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 152615/152615 [00:00<00:00, 212473.75 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                                                                                                              \u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):   0%|                                                                                                                                                                                       | 0/16958 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16958/16958 [00:00<00:00, 209322.06 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                                                                                                              \u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "parquet_file = \"/opt/home/bo_ling/dataset/modeling_data_v1.parquet\"\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "count = 0\n",
    "\n",
    "def gen():\n",
    "    for index, row in df.iterrows():\n",
    "        yield {\"text\": row['context_and_msg']}\n",
    "dataset = Dataset.from_generator(gen)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "    \n",
    "dataset.save_to_disk(\"/opt/home/bo_ling/dataset/modeling_data_v1.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ccf57b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 152615\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 16958\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = load_from_disk(\"/opt/home/bo_ling/dataset/modeling_data_v1.hf\")\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14764d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Specific Information: The restaurant name is Insomnia Cookies (164 Orchard St) and the order value is $19.93. The estimated delivery time is 01:45 and latest arrival time is 02:05. Order status is 6.\\n\\n###\\n\\nagent: Hi Charlotte, welcome to the chat support team. I'll be assisting you today. <|endofsentence|>\\nagent: May I know your concern please? <|endofsentence|>\\nagent: Charlotte, Are we still connected? <|endofsentence|>\\nagent: I'm grateful that I was able to help you out today, Charlotte. As I have not heard back from you in a while, I am closing the chat. Please feel free to contact us again for any issues. Thank you for chatting with us today. Stay safe, stay healthy. <|endofsentence|>\\nagent: Yes No <|endofsentence|>\\nagent: Have we resolved this issue? <|endofsentence|>\\n\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee6a904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (/home/prodadmin/.cache/huggingface/datasets/generator/default-71e7c02640b57610/0.0.0)\n",
      "                                                                                                                                                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "import json \n",
    "data = []\n",
    "max_question_length=500\n",
    "max_answer_length=500\n",
    "with open(\"/opt/home/bo_ling/dataset/gds_v4.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "for d in json_data:\n",
    "    try:\n",
    "        instruction = d['instruction'].strip().replace(\":\", \" input:\")\n",
    "        input_text = d[\"ocr_text\"][:max_question_length]\n",
    "        output_text = \"\\n\" + d[\"output\"][:max_answer_length]\n",
    "        text = PROMPT_FORMAT.format(instruction=instruction,input_text=input_text,output_text=output_text)\n",
    "        data.append({\n",
    "                \"instruction\": instruction,\n",
    "                \"input\": input_text, \n",
    "                \"output\": output_text,\n",
    "                \"text\": text\n",
    "            })\n",
    "    except:\n",
    "        pass\n",
    "def gen():\n",
    "    for d in data:\n",
    "        yield d\n",
    "dataset = Dataset.from_generator(gen)\n",
    "dataset.save_to_disk(\"/opt/home/bo_ling/dataset/gds_v4.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b1fa4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uuid': 'c65024cc-26bc-490a-91d2-62f840fc0f8b',\n",
       " 'field': 'address_line1',\n",
       " 'instruction': 'Extract address from the following: ',\n",
       " 'ocr_text': 'California DRIVER LICENSE 081202 LN SOTO MUNGUIA FN ALEC PIERRE 9939 VAN RUITEN ST BELLFLOWER, CA 90706 SEX M AM DONOR USA DLY7679862 EXP 08/12/2025 DOB 08/12/2002 AGE 2 IN 7023 DD 08/04/2021606A3/E5FD/25 CLASS C END NONE RSTR NONE 08122002 HAIR BRN EYES HZL HGT 5\\'-11\" WGT 205 lb FEDERAL LIMITS APPLY ISS 10/14/2021',\n",
       " 'output': '9939 VAN RUITEN ST'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3ec59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Extract address from the following input:',\n",
       " 'input': 'California DRIVER LICENSE 081202 LN SOTO MUNGUIA FN ALEC PIERRE 9939 VAN RUITEN ST BELLFLOWER, CA 90706 SEX M AM DONOR USA DLY7679862 EXP 08/12/2025 DOB 08/12/2002 AGE 2 IN 7023 DD 08/04/2021606A3/E5FD/25 CLASS C END NONE RSTR NONE 08122002 HAIR BRN EYES HZL HGT 5\\'-11\" WGT 205 lb FEDERAL LIMITS APPLY ISS 10/14/2021',\n",
       " 'output': '\\n9939 VAN RUITEN ST',\n",
       " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nExtract address from the following input:\\nCalifornia DRIVER LICENSE 081202 LN SOTO MUNGUIA FN ALEC PIERRE 9939 VAN RUITEN ST BELLFLOWER, CA 90706 SEX M AM DONOR USA DLY7679862 EXP 08/12/2025 DOB 08/12/2002 AGE 2 IN 7023 DD 08/04/2021606A3/E5FD/25 CLASS C END NONE RSTR NONE 08122002 HAIR BRN EYES HZL HGT 5\\'-11\" WGT 205 lb FEDERAL LIMITS APPLY ISS 10/14/2021\\n\\n### Response:\\n9939 VAN RUITEN ST\\n'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226441b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
