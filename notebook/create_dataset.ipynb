{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb577b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bo_ling/python39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(\"...\"))\n",
    "sys.path.append(os.path.dirname(SCRIPT_DIR))\n",
    "from training.generate import (generate_response, load_model_tokenizer_for_generate, \n",
    "                               get_special_token_id, get_special_token_id)\n",
    "from training.transcript_trainer import PROMPT_FORMAT, create_data_set_from_json_list\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "abeaf94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /home/prodadmin/.cache/huggingface/datasets/generator/default-71d75ecb741b2dcb/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/prodadmin/.cache/huggingface/datasets/generator/default-71d75ecb741b2dcb/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "file_to_instruction_map = {\n",
    "    \"/opt/home/bo_ling/dataset/michelangelo_so_long.jsonl\": \"Please answer the following MA helpdesk questions:\",\n",
    "    \"/opt/home/bo_ling/dataset/docstrans.jsonl\": \"Please finish the following doc translation tasks:\",\n",
    "    \"/opt/home/bo_ling/dataset/eats_goldenset.jsonl\": \"Please answer Uber eats products relation questions:\"\n",
    "}\n",
    "json_file = \"/opt/home/bo_ling/dataset/eats_goldenset.jsonl\"\n",
    "dataset_file = json_file.replace(\".jsonl\", \".hf\")\n",
    "dataset = create_data_set_from_json_list(json_file,\n",
    "                                         file_to_instruction_map=file_to_instruction_map) \n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "dataset.save_to_disk(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4366efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /home/prodadmin/.cache/huggingface/datasets/generator/default-f24c58b0e2ee275b/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/prodadmin/.cache/huggingface/datasets/generator/default-f24c58b0e2ee275b/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = []\n",
    "max_question_length=2000\n",
    "max_answer_length=2000\n",
    "with open(\"/opt/home/bo_ling/dataset/doc_transcript_pii_data.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "for d in json_data:\n",
    "    try:\n",
    "        instruction = d['instruction']+\":\"\n",
    "        input_text = d[\"input\"][:max_question_length]\n",
    "        output_text = \"\\n\" + d[\"output\"][:max_answer_length]\n",
    "        text = PROMPT_FORMAT.format(instruction=instruction,input_text=input_text,output_text=output_text)\n",
    "        data.append({\n",
    "                \"instruction\": instruction,\n",
    "                \"input\": input_text, \n",
    "                \"output\": output_text,\n",
    "                \"text\": text\n",
    "            })\n",
    "    except:\n",
    "        pass\n",
    "def gen():\n",
    "    for d in data:\n",
    "        yield d\n",
    "dataset = Dataset.from_generator(gen)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "dataset.save_to_disk(\"/opt/home/bo_ling/dataset/doc_transcript_pii_data_simplify.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e884cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text'],\n",
       "        num_rows: 629797\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text'],\n",
       "        num_rows: 69978\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = load_from_disk(\"/opt/home/bo_ling/dataset/doc_transcript_pii_data_simplify.hf\")\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a550e946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Extract address from the following input:',\n",
       " 'input': 'UTAH James J. Brunkan DRIVER LICENSE 4d 154045998 3 DOB 06/03/1966 BRUNKOW 2JAMES JOSEPH 81562 W 1000 N SALT LAKE CITY, UT 84116 5 DD 53339121 9 CLASS D 15 SEX M 16 HGT 6\\'-02\" 17 WGT 250 lb 18 EYES BLU 19 HAIR BRO I COMMISSIONER OF PUBLIC SAFETY 4a ISS 03/10/2018 4b EXP 06/03/2023 9a END NONE 12 REST B UT USA 06/03/66 DONOR Y',\n",
       " 'output': '\\n1562 W 1000 N',\n",
       " 'text': 'Extract address from the following input:\\nUTAH James J. Brunkan DRIVER LICENSE 4d 154045998 3 DOB 06/03/1966 BRUNKOW 2JAMES JOSEPH 81562 W 1000 N SALT LAKE CITY, UT 84116 5 DD 53339121 9 CLASS D 15 SEX M 16 HGT 6\\'-02\" 17 WGT 250 lb 18 EYES BLU 19 HAIR BRO I COMMISSIONER OF PUBLIC SAFETY 4a ISS 03/10/2018 4b EXP 06/03/2023 9a END NONE 12 REST B UT USA 06/03/66 DONOR Y\\n\\n### Response:\\n:\\n1562 W 1000 N\\n'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a174c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /home/prodadmin/.cache/huggingface/datasets/generator/default-7895c5e842d084b9/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 1796 examples [00:00, 17886.03 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 4053 examples [00:00, 20631.90 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 6371 examples [00:00, 21793.42 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 8686 examples [00:00, 22327.86 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 11000 examples [00:00, 22468.39 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 13360 examples [00:00, 22846.81 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 15714 examples [00:00, 23069.83 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 19192 examples [00:00, 23077.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 21533 examples [00:00, 23166.52 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 23885 examples [00:01, 23264.08 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 27380 examples [00:01, 23230.48 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 29736 examples [00:01, 23316.73 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 33173 examples [00:01, 23167.25 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 35542 examples [00:01, 23298.82 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 37882 examples [00:01, 23322.73 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 41400 examples [00:01, 23169.30 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 43775 examples [00:01, 23314.00 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 47274 examples [00:02, 23315.32 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 49643 examples [00:02, 23408.09 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 52000 examples [00:02, 23305.93 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 54378 examples [00:02, 23432.59 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 56736 examples [00:02, 23471.60 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 60223 examples [00:02, 23384.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 62580 examples [00:02, 23431.83 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 64971 examples [00:02, 23559.78 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 68418 examples [00:02, 23341.39 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 70796 examples [00:03, 23453.60 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 74249 examples [00:03, 23295.69 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 76604 examples [00:03, 23357.44 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 78976 examples [00:03, 23451.69 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 82485 examples [00:03, 23426.45 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 85944 examples [00:03, 23298.92 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 89410 examples [00:03, 23233.97 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 91770 examples [00:03, 23320.59 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 95240 examples [00:04, 23253.33 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 97599 examples [00:04, 23332.98 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 99963 examples [00:04, 23411.33 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 103419 examples [00:04, 23277.09 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 105772 examples [00:04, 23340.77 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 109126 examples [00:04, 22945.00 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 111484 examples [00:04, 23102.58 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 113848 examples [00:04, 23241.90 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 117363 examples [00:05, 23153.40 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 119703 examples [00:05, 23215.88 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 123196 examples [00:05, 23204.27 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 125565 examples [00:05, 23323.81 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 127921 examples [00:05, 23383.84 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 131398 examples [00:05, 23211.10 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 133759 examples [00:05, 23308.83 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 137273 examples [00:05, 23348.45 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 139655 examples [00:06, 23464.80 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 143197 examples [00:06, 23321.86 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 145564 examples [00:06, 23406.01 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 147922 examples [00:06, 23448.37 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 151399 examples [00:06, 23260.50 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 153761 examples [00:06, 23351.04 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 157197 examples [00:06, 23189.18 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 159538 examples [00:06, 23242.26 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 163000 examples [00:07, 23095.79 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 165351 examples [00:07, 23196.46 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 168810 examples [00:07, 23145.83 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                    \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/prodadmin/.cache/huggingface/datasets/generator/default-7895c5e842d084b9/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Saving the dataset (0/1 shards):   0%|                                                                                                                                                                                      | 0/152615 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  12%|███████████████████▌                                                                                                                                                  | 18000/152615 [00:00<00:00, 173411.10 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  26%|███████████████████████████████████████████▌                                                                                                                          | 40000/152615 [00:00<00:00, 195499.43 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  41%|███████████████████████████████████████████████████████████████████▍                                                                                                  | 62000/152615 [00:00<00:00, 204141.24 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  55%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 84000/152615 [00:00<00:00, 208141.68 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                  | 106000/152615 [00:00<00:00, 210292.04 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 128000/152615 [00:00<00:00, 212110.46 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 150000/152615 [00:00<00:00, 212473.75 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 152615/152615 [00:00<00:00, 212473.75 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                                                                                                              \u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (0/1 shards):   0%|                                                                                                                                                                                       | 0/16958 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16958/16958 [00:00<00:00, 209322.06 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                                                                                                              \u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "parquet_file = \"/opt/home/bo_ling/dataset/modeling_data_v1.parquet\"\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "count = 0\n",
    "\n",
    "def gen():\n",
    "    for index, row in df.iterrows():\n",
    "        yield {\"text\": row['context_and_msg']}\n",
    "dataset = Dataset.from_generator(gen)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "    \n",
    "dataset.save_to_disk(\"/opt/home/bo_ling/dataset/modeling_data_v1.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ede512e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 152615\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 16958\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = load_from_disk(\"/opt/home/bo_ling/dataset/modeling_data_v1.hf\")\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee6a904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /home/prodadmin/.cache/huggingface/datasets/generator/default-dd0ec69f9326ee46/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/prodadmin/.cache/huggingface/datasets/generator/default-dd0ec69f9326ee46/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "import json \n",
    "data = []\n",
    "max_question_length=2000\n",
    "max_answer_length=2000\n",
    "with open(\"/opt/home/bo_ling/dataset/gds_v4.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "for d in json_data:\n",
    "    try:\n",
    "        instruction = d['instruction'].strip().replace(\":\", \" input:\")\n",
    "        input_text = d[\"ocr_text\"][:max_question_length]\n",
    "        output_text = \"\\n\" + d[\"output\"][:max_answer_length]\n",
    "        text = PROMPT_FORMAT.format(instruction=instruction,input_text=input_text,output_text=output_text)\n",
    "        data.append({\n",
    "                \"instruction\": instruction,\n",
    "                \"input\": input_text, \n",
    "                \"output\": output_text,\n",
    "                \"text\": text\n",
    "            })\n",
    "    except:\n",
    "        pass\n",
    "def gen():\n",
    "    for d in data:\n",
    "        yield d\n",
    "dataset = Dataset.from_generator(gen)\n",
    "dataset.save_to_disk(\"/opt/home/bo_ling/dataset/gds_v4_simplify.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dfa2bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text'],\n",
       "    num_rows: 182662\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = load_from_disk(\"/opt/home/bo_ling/dataset/gds_v4_simplify.hf\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9b1fa4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extract dob from the following input:': 75,\n",
       " 'Extract issue date from the following input:': 75,\n",
       " 'Extract expiration date from the following input:': 75,\n",
       " 'Extract first name from the following input:': 74,\n",
       " 'Extract middle name from the following input:': 64,\n",
       " 'Extract last name from the following input:': 74,\n",
       " 'Extract license class from the following input:': 74,\n",
       " 'Extract drivers license number from the following input:': 74,\n",
       " 'Extract zip from the following input:': 74,\n",
       " 'Extract driving licence issue state from the following input:': 74,\n",
       " 'Extract address from the following input:': 74,\n",
       " 'Extract gender from the following input:': 74,\n",
       " 'Extract city from the following input:': 74,\n",
       " 'Is the driving license valid for identification?': 44}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "ins_count = {}\n",
    "for d in dataset:\n",
    "    count += 1\n",
    "    if count >=1000:\n",
    "        break\n",
    "    instruction = d['instruction']\n",
    "    ins_count[instruction] = ins_count.get(instruction, 0) + 1\n",
    "ins_count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7797e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /home/prodadmin/.cache/huggingface/datasets/generator/default-ead54ea4939cc760/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train split: 7909 examples [00:00, 78904.96 examples/s]\u001b[A\n",
      "Generating train split: 19164 examples [00:00, 98652.93 examples/s]\u001b[A\n",
      "Generating train split: 36510 examples [00:00, 108104.08 examples/s]\u001b[A\n",
      "Generating train split: 48000 examples [00:00, 110330.89 examples/s]\u001b[A\n",
      "Generating train split: 59525 examples [00:00, 111949.49 examples/s]\u001b[A\n",
      "Generating train split: 71000 examples [00:00, 112801.47 examples/s]\u001b[A\n",
      "Generating train split: 82521 examples [00:00, 113558.29 examples/s]\u001b[A\n",
      "Generating train split: 94148 examples [00:00, 114379.95 examples/s]\u001b[A\n",
      "Generating train split: 105970 examples [00:00, 115541.35 examples/s]\u001b[A\n",
      "Generating train split: 117675 examples [00:01, 116000.65 examples/s]\u001b[A\n",
      "Generating train split: 135072 examples [00:01, 115967.78 examples/s]\u001b[A\n",
      "Generating train split: 152210 examples [00:01, 115337.20 examples/s]\u001b[A\n",
      "Generating train split: 163937 examples [00:01, 115795.80 examples/s]\u001b[A\n",
      "Generating train split: 181292 examples [00:01, 115742.08 examples/s]\u001b[A\n",
      "Generating train split: 192994 examples [00:01, 115888.71 examples/s]\u001b[A\n",
      "Generating train split: 210291 examples [00:01, 115680.73 examples/s]\u001b[A\n",
      "Generating train split: 222000 examples [00:01, 115860.83 examples/s]\u001b[A\n",
      "Generating train split: 233901 examples [00:02, 116672.85 examples/s]\u001b[A\n",
      "Generating train split: 245593 examples [00:02, 116730.49 examples/s]\u001b[A\n",
      "Generating train split: 263000 examples [00:02, 116339.89 examples/s]\u001b[A\n",
      "Generating train split: 274653 examples [00:02, 116389.04 examples/s]\u001b[A\n",
      "Generating train split: 292000 examples [00:02, 115805.59 examples/s]\u001b[A\n",
      "Generating train split: 303644 examples [00:02, 115955.00 examples/s]\u001b[A\n",
      "Generating train split: 320988 examples [00:02, 115810.87 examples/s]\u001b[A\n",
      "Generating train split: 338410 examples [00:02, 115906.00 examples/s]\u001b[A\n",
      "Generating train split: 355686 examples [00:03, 115625.44 examples/s]\u001b[A\n",
      "Generating train split: 373001 examples [00:03, 115559.16 examples/s]\u001b[A\n",
      "Generating train split: 384771 examples [00:03, 116045.40 examples/s]\u001b[A\n",
      "Generating train split: 402070 examples [00:03, 115802.16 examples/s]\u001b[A\n",
      "Generating train split: 419476 examples [00:03, 115848.08 examples/s]\u001b[A\n",
      "Generating train split: 437000 examples [00:03, 116075.59 examples/s]\u001b[A\n",
      "Generating train split: 448670 examples [00:03, 116215.38 examples/s]\u001b[A\n",
      "Generating train split: 466000 examples [00:04, 115710.82 examples/s]\u001b[A\n",
      "Generating train split: 483424 examples [00:04, 115837.88 examples/s]\u001b[A\n",
      "Generating train split: 500900 examples [00:04, 115867.76 examples/s]\u001b[A\n",
      "Generating train split: 518059 examples [00:04, 115401.67 examples/s]\u001b[A\n",
      "Generating train split: 529718 examples [00:04, 115662.04 examples/s]\u001b[A\n",
      "Generating train split: 547000 examples [00:04, 115218.82 examples/s]\u001b[A\n",
      "Generating train split: 564183 examples [00:04, 114991.32 examples/s]\u001b[A\n",
      "Generating train split: 576000 examples [00:05, 115178.33 examples/s]\u001b[A\n",
      "Generating train split: 587725 examples [00:05, 115682.24 examples/s]\u001b[A\n",
      "Generating train split: 605000 examples [00:05, 115392.82 examples/s]\u001b[A\n",
      "Generating train split: 616602 examples [00:05, 115536.84 examples/s]\u001b[A\n",
      "Generating train split: 634000 examples [00:05, 115596.96 examples/s]\u001b[A\n",
      "Generating train split: 645828 examples [00:05, 116263.05 examples/s]\u001b[A\n",
      "Generating train split: 663301 examples [00:05, 116336.86 examples/s]\u001b[A\n",
      "Generating train split: 675000 examples [00:05, 116193.40 examples/s]\u001b[A\n",
      "Generating train split: 692478 examples [00:06, 116278.61 examples/s]\u001b[A\n",
      "Generating train split: 710000 examples [00:06, 116249.56 examples/s]\u001b[A\n",
      "Generating train split: 721670 examples [00:06, 116348.92 examples/s]\u001b[A\n",
      "Generating train split: 738939 examples [00:06, 115917.01 examples/s]\u001b[A\n",
      "Generating train split: 756443 examples [00:06, 116146.91 examples/s]\u001b[A\n",
      "Generating train split: 774000 examples [00:06, 116116.09 examples/s]\u001b[A\n",
      "Generating train split: 785633 examples [00:06, 116165.53 examples/s]\u001b[A\n",
      "Generating train split: 797473 examples [00:06, 116716.33 examples/s]\u001b[A\n",
      "Generating train split: 815048 examples [00:07, 116862.66 examples/s]\u001b[A\n",
      "Generating train split: 826777 examples [00:07, 116943.55 examples/s]\u001b[A\n",
      "Generating train split: 844131 examples [00:07, 116508.63 examples/s]\u001b[A\n",
      "Generating train split: 855835 examples [00:07, 116628.33 examples/s]\u001b[A\n",
      "Generating train split: 867537 examples [00:07, 116721.41 examples/s]\u001b[A\n",
      "Generating train split: 885000 examples [00:07, 116584.77 examples/s]\u001b[A\n",
      "Generating train split: 896817 examples [00:07, 116974.35 examples/s]\u001b[A\n",
      "Generating train split: 914261 examples [00:07, 116720.72 examples/s]\u001b[A\n",
      "Generating train split: 925984 examples [00:08, 116560.75 examples/s]\u001b[A\n",
      "Generating train split: 943521 examples [00:08, 116668.65 examples/s]\u001b[A\n",
      "Generating train split: 961000 examples [00:08, 116583.77 examples/s]\u001b[A\n",
      "Generating train split: 972673 examples [00:08, 116603.55 examples/s]\u001b[A\n",
      "Generating train split: 990209 examples [00:08, 116695.53 examples/s]\u001b[A\n",
      "Generating train split: 1002000 examples [00:08, 116592.80 examples/s]\u001b[A\n",
      "Generating train split: 1013694 examples [00:08, 116664.66 examples/s]\u001b[A\n",
      "Generating train split: 1031401 examples [00:08, 117155.90 examples/s]\u001b[A\n",
      "Generating train split: 1049010 examples [00:09, 117208.45 examples/s]\u001b[A\n",
      "Generating train split: 1060737 examples [00:09, 117214.27 examples/s]\u001b[A\n",
      "Generating train split: 1078212 examples [00:09, 116961.70 examples/s]\u001b[A\n",
      "Generating train split: 1090011 examples [00:09, 116876.07 examples/s]\u001b[A\n",
      "Generating train split: 1101865 examples [00:09, 117293.08 examples/s]\u001b[A\n",
      "Generating train split: 1119199 examples [00:09, 116647.03 examples/s]\u001b[A\n",
      "Generating train split: 1131000 examples [00:09, 116361.07 examples/s]\u001b[A\n",
      "Generating train split: 1142763 examples [00:09, 116677.39 examples/s]\u001b[A\n",
      "Generating train split: 1160411 examples [00:10, 117014.08 examples/s]\u001b[A\n",
      "Generating train split: 1172137 examples [00:10, 117072.95 examples/s]\u001b[A\n",
      "Generating train split: 1189495 examples [00:10, 116571.43 examples/s]\u001b[A\n",
      "Generating train split: 1202441 examples [00:10, 82520.31 examples/s] \u001b[A\n",
      "Generating train split: 1214000 examples [00:10, 89029.16 examples/s]\u001b[A\n",
      "Generating train split: 1225638 examples [00:10, 95067.80 examples/s]\u001b[A\n",
      "Generating train split: 1237108 examples [00:10, 99773.43 examples/s]\u001b[A\n",
      "Generating train split: 1249000 examples [00:10, 104412.61 examples/s]\u001b[A\n",
      "Generating train split: 1260913 examples [00:11, 108319.84 examples/s]\u001b[A\n",
      "Generating train split: 1272527 examples [00:11, 110473.39 examples/s]\u001b[A\n",
      "Generating train split: 1284051 examples [00:11, 111803.12 examples/s]\u001b[A\n",
      "Generating train split: 1296000 examples [00:11, 113367.93 examples/s]\u001b[A\n",
      "Generating train split: 1307646 examples [00:11, 114245.58 examples/s]\u001b[A\n",
      "Generating train split: 1325104 examples [00:11, 115035.10 examples/s]\u001b[A\n",
      "Generating train split: 1337000 examples [00:11, 115596.35 examples/s]\u001b[A\n",
      "Generating train split: 1348841 examples [00:11, 116366.93 examples/s]\u001b[A\n",
      "Generating train split: 1360607 examples [00:11, 116717.56 examples/s]\u001b[A\n",
      "Generating train split: 1378000 examples [00:12, 116066.49 examples/s]\u001b[A\n",
      "Generating train split: 1389755 examples [00:12, 116454.70 examples/s]\u001b[A\n",
      "Generating train split: 1407334 examples [00:12, 116721.02 examples/s]\u001b[A\n",
      "Generating train split: 1425000 examples [00:12, 116721.76 examples/s]\u001b[A\n",
      "Generating train split: 1436712 examples [00:12, 116805.96 examples/s]\u001b[A\n",
      "Generating train split: 1454137 examples [00:12, 116566.89 examples/s]\u001b[A\n",
      "Generating train split: 1465919 examples [00:12, 116848.56 examples/s]\u001b[A\n",
      "Generating train split: 1477639 examples [00:12, 116925.28 examples/s]\u001b[A\n",
      "Generating train split: 1489373 examples [00:13, 117015.95 examples/s]\u001b[A\n",
      "Generating train split: 1507000 examples [00:13, 116601.17 examples/s]\u001b[A\n",
      "Generating train split: 1518674 examples [00:13, 116636.90 examples/s]\u001b[A\n",
      "Generating train split: 1536000 examples [00:13, 116124.39 examples/s]\u001b[A\n",
      "Generating train split: 1547888 examples [00:13, 116806.89 examples/s]\u001b[A\n",
      "Generating train split: 1565547 examples [00:13, 117110.14 examples/s]\u001b[A\n",
      "Generating train split: 1583258 examples [00:13, 117405.07 examples/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1600766 examples [00:13, 117178.46 examples/s]\u001b[A\n",
      "Generating train split: 1618152 examples [00:14, 116753.17 examples/s]\u001b[A\n",
      "Generating train split: 1630000 examples [00:14, 116928.28 examples/s]\u001b[A\n",
      "Generating train split: 1641778 examples [00:14, 117133.87 examples/s]\u001b[A\n",
      "Generating train split: 1658143 examples [00:14, 113817.48 examples/s]\u001b[A\n",
      "                                                                      \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/prodadmin/.cache/huggingface/datasets/generator/default-ead54ea4939cc760/0.0.0. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset generator/default to /home/prodadmin/.cache/huggingface/datasets/generator/default-46880ca7efe99230/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train split: 11000 examples [00:00, 108369.26 examples/s]\u001b[A\n",
      "Generating train split: 22683 examples [00:00, 113255.44 examples/s]\u001b[A\n",
      "Generating train split: 34056 examples [00:00, 113466.96 examples/s]\u001b[A\n",
      "Generating train split: 45769 examples [00:00, 114843.03 examples/s]\u001b[A\n",
      "Generating train split: 57403 examples [00:00, 115344.20 examples/s]\u001b[A\n",
      "Generating train split: 69000 examples [00:00, 115483.80 examples/s]\u001b[A\n",
      "Generating train split: 80800 examples [00:00, 116289.92 examples/s]\u001b[A\n",
      "Generating train split: 98010 examples [00:00, 115634.69 examples/s]\u001b[A\n",
      "Generating train split: 115370 examples [00:01, 115667.31 examples/s]\u001b[A\n",
      "Generating train split: 126977 examples [00:01, 115643.15 examples/s]\u001b[A\n",
      "Generating train split: 138764 examples [00:01, 116223.13 examples/s]\u001b[A\n",
      "Generating train split: 150516 examples [00:01, 116584.72 examples/s]\u001b[A\n",
      "Generating train split: 168000 examples [00:01, 116325.34 examples/s]\u001b[A\n",
      "Generating train split: 184734 examples [00:01, 115647.32 examples/s]\u001b[A\n",
      "                                                                     \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/prodadmin/.cache/huggingface/datasets/generator/default-46880ca7efe99230/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the dataset (0/3 shards):   0%|                                                                                                                                                                                     | 0/1658143 [00:00<?, ? examples/s]\u001b[A\n",
      "Saving the dataset (0/3 shards):  10%|████████████████▌                                                                                                                                                  | 169000/1658143 [00:00<00:00, 1633661.08 examples/s]\u001b[A\n",
      "Saving the dataset (0/3 shards):  20%|█████████████████████████████████                                                                                                                                  | 336000/1658143 [00:00<00:00, 1653590.65 examples/s]\u001b[A\n",
      "Saving the dataset (0/3 shards):  30%|█████████████████████████████████████████████████▋                                                                                                                 | 505000/1658143 [00:00<00:00, 1665159.49 examples/s]\u001b[A\n",
      "Saving the dataset (1/3 shards):  33%|██████████████████████████████████████████████████████▎                                                                                                            | 552715/1658143 [00:00<00:00, 1665159.49 examples/s]\u001b[A\n",
      "                                                                                                                                                                                                                                                              \u001b[A\n",
      "Saving the dataset (0/1 shards):   0%|                                                                                                                                                                                      | 0/184734 [00:00<?, ? examples/s]\u001b[A\n",
      "Saving the dataset (0/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 184000/184734 [00:00<00:00, 1792916.48 examples/s]\u001b[A\n",
      "Saving the dataset (1/1 shards): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 184734/184734 [00:00<00:00, 1792916.48 examples/s]\u001b[A\n",
      "                                                                                                                                                                                                                                                              \u001b[A"
     ]
    }
   ],
   "source": [
    "parquet_file = \"/opt/home/bo_ling/dataset/modeling_data_v1.parquet\"\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from training.agent_trainer import generate_data_from_chat\n",
    "train, test = train_test_split(df, test_size=0.1)\n",
    "count = 0\n",
    "\n",
    "def train_gen():\n",
    "    for index, row in train.iterrows():\n",
    "        for d in generate_data_from_chat(row['context_and_msg']):\n",
    "            yield {\"text\": d}\n",
    "def test_gen():\n",
    "    for index, row in test.iterrows():\n",
    "        for d in generate_data_from_chat(row['context_and_msg']):\n",
    "            yield {\"text\": d}\n",
    "train_dataset = Dataset.from_generator(train_gen)\n",
    "test_dataset = Dataset.from_generator(test_gen)\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "    \n",
    "dataset.save_to_disk(\"/opt/home/bo_ling/dataset/modeling_data_v1_expanded.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137c041a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1658143\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 184734\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = load_from_disk(\"/opt/home/bo_ling/dataset/modeling_data_v1_expanded.hf\")\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8037bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Specific Information: The restaurant name is Epic Wings- Vista and the order value is $58.6. The estimated delivery time is 20:10 and latest arrival time is 20:20. Order status is 4.\\n\\nAngelica: Hi aakash I been trying to contact my delivery person that has been in the same spot for idk how long already \\n\\nAngelica: No response but reading my messages \\n\\nAngelica: And I asked for priority \\n\\nAngelica: While shes been in the same spot near where she should be picking up my food \\n\\nAngelica: I want to know if theres a problem \\n\\nAngelica: I want her to cancel my pickup if she cant fulfill what Im lying for \\n\\nAngelica: *paying \\n\\nAngelica: Taking way longer than it should \\n\\nAngelica: Ok \\n\\nAngelica: I just wished the lady responded she read my message \\nagent: Are we still connected? <|endofsentence|>'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['train'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13758dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
