{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df372c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(\"...\"))\n",
    "sys.path.append(os.path.dirname(SCRIPT_DIR))\n",
    "\n",
    "from training.agent_trainer import END_KEY, RESPONSE_KEY_NL, CHAT_START_KEY\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "from transformers.data.metrics.squad_metrics import compute_exact, compute_f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f3fbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'ticket_uuid'],\n",
       "    num_rows: 6282\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_data = load_from_disk(\"/opt/home/bo_ling/dataset/modeling_data_v2.hf\")['test']\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e560587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_output_dir=\"/opt/home/bo_ling/modeling_data_v1_2048_checkpoint-53600\"\n",
    "#model, tokenizer = load_model_tokenizer_for_generate(local_output_dir)\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_output_dir, padding_side=\"left\")\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModelForCausalLM.from_pretrained(local_output_dir, trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb0b69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endofsentence|> [50400]\n"
     ]
    }
   ],
   "source": [
    "eos_token_id = tokenizer.encode(END_KEY)\n",
    "print(END_KEY, eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3c253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agent_response(\n",
    "    texts: str,\n",
    "    model: PreTrainedModel,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    do_sample: bool = True,\n",
    "    max_new_tokens: int = 256,\n",
    "    top_p: float = 0.92,\n",
    "    top_k: int = 0,\n",
    "    **kwargs,\n",
    ") -> str:\n",
    "    #texts = texts.replace(END_KEY, \"\")\n",
    "    input_ids = tokenizer(texts, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    response_key_token_id = tokenizer.encode(RESPONSE_KEY_NL)[0]\n",
    "    end_key_token_id = tokenizer.encode(END_KEY)[0]\n",
    "    gen_tokens = model.generate(\n",
    "        input_ids,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        # Ensure generation stops once it generates \"### End\"\n",
    "        eos_token_id=end_key_token_id,\n",
    "        do_sample=do_sample,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        **kwargs,\n",
    "    )[0].cpu()\n",
    "\n",
    "    # The response will be set to this variable if we can identify it.\n",
    "    question_size = len(input_ids[0])\n",
    "    decoded = tokenizer.decode(gen_tokens[question_size:]).strip()\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3636b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generated_chats(chat_str):\n",
    "    chats = chat_str.replace(\"\\n\\n###\\n\", END_KEY).split(END_KEY)\n",
    "    curr_text = chats[0] + END_KEY\n",
    "    print(chats[0])\n",
    "    for chat in chats[1:]:\n",
    "        print(chat)\n",
    "        if chat.startswith(RESPONSE_KEY_NL):\n",
    "            generated = generate_agent_response(curr_text, model, tokenizer).strip(END_KEY)\n",
    "            if generated.replace(\"\\n\", \"\").startswith(RESPONSE_KEY_NL.replace(\"\\n\", \"\")):\n",
    "                print(\"\\n\")\n",
    "                print(\"*\"*40 + \"START OUTPUT GENERATED\" + \"*\"*40)\n",
    "                print(generated)\n",
    "                print(\"*\"*40 + \"END OUTPUT GENERATED\" + \"*\"*40)\n",
    "                print(\"\\n\")\n",
    "        curr_text += chat + END_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4709e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scores': [{'exact': 0, 'f1': 0.3125, 'type': 'active'},\n",
       "  {'exact': 0, 'f1': 0.6666666666666666, 'type': 'active'},\n",
       "  {'exact': 1, 'f1': 1.0, 'type': 'active'},\n",
       "  {'exact': 0.0, 'f1': 0.0, 'type': 'silent'},\n",
       "  {'exact': 0, 'f1': 0.14545454545454545, 'type': 'active'},\n",
       "  {'exact': 0, 'f1': 0.21505376344086022, 'type': 'active'},\n",
       "  {'exact': 0, 'f1': 0.22857142857142854, 'type': 'active'},\n",
       "  {'exact': 0.0, 'f1': 0.0, 'type': 'silent'},\n",
       "  {'exact': 0, 'f1': 0.3768115942028986, 'type': 'active'}],\n",
       " 'avg_f1_score': 0.32722866648182214,\n",
       " 'avg_exact_score': 0.1111111111111111,\n",
       " 'missed': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(chat_str):\n",
    "    chats = chat_str.replace(\"\\n\\n###\\n\", END_KEY).split(END_KEY)\n",
    "    curr_text = chats[0] + END_KEY\n",
    "    scores = []\n",
    "    total_missed = 0\n",
    "    total_f1 = 0\n",
    "    total_exact = 0\n",
    "    total = 0\n",
    "    for i, chat in enumerate(chats[1:]):\n",
    "        if chat.startswith(RESPONSE_KEY_NL):\n",
    "            generated = generate_agent_response(curr_text, model, tokenizer).strip(END_KEY)\n",
    "            if generated.replace(\"\\n\", \"\").startswith(RESPONSE_KEY_NL.replace(\"\\n\", \"\")):\n",
    "                exact_score = compute_exact(generated, chat)\n",
    "                f1_score = compute_f1(generated, chat)\n",
    "                scores.append({\"exact\": exact_score, \"f1\": f1_score, \"type\": \"active\"})\n",
    "                total_f1 += f1_score\n",
    "                total_exact += exact_score\n",
    "            else:\n",
    "                scores.append({\"exact\": 0.0, \"f1\": 0.0, \"type\": \"silent\"})\n",
    "                total_missed += 1\n",
    "            total += 1\n",
    "        curr_text += chat + END_KEY\n",
    "    \n",
    "    return {\"scores\": scores, \n",
    "            \"avg_f1_score\": total_f1/total, \n",
    "            \"avg_exact_score\": total_exact/total,\n",
    "            \"missed\": total_missed,\n",
    "           }\n",
    "compute_metrics(test_data[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32218463",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = {}\n",
    "outputs = []\n",
    "count  = 0\n",
    "import json\n",
    "for d in test_data:\n",
    "    count += 1\n",
    "    scores = compute_metrics(d['text'])\n",
    "    scores[\"ticket_uuid\"] = d[\"ticket_uuid\"]\n",
    "    outputs.append(scores)\n",
    "    if count%100 == 0:\n",
    "        with open(f'/opt/home/bo_ling/co_model_eval/agent_v1_2048L_{count}C.json', 'w') as f:\n",
    "            json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6db9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4905ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/opt/home/bo_ling/co_model_eval/agent_v1_2048L_400C.json', 'r') as f:\n",
    "    outputs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa0d4bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286946690840082 0.43090462370548976 0.2495591078133538\n"
     ]
    }
   ],
   "source": [
    "missed_rate = 0\n",
    "f1_score = 0.0\n",
    "exact_score = 0.0\n",
    "for d in outputs:\n",
    "    missed_rate += d['missed']/len(d['scores'])\n",
    "    f1_score += d['avg_f1_score']\n",
    "    exact_score += d['avg_exact_score']\n",
    "print(missed_rate/len(outputs), f1_score/len(outputs), exact_score/len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55925979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2904717562978118 0.43366429365621634 0.2532833605226647\n"
     ]
    }
   ],
   "source": [
    "with open(f'/opt/home/bo_ling/co_model_eval/agent_v1_1536L_400C.json', 'r') as f:\n",
    "    outputs = json.load(f)\n",
    "missed_rate = 0\n",
    "f1_score = 0.0\n",
    "exact_score = 0.0\n",
    "for d in outputs:\n",
    "    missed_rate += d['missed']/len(d['scores'])\n",
    "    f1_score += d['avg_f1_score']\n",
    "    exact_score += d['avg_exact_score']\n",
    "print(missed_rate/len(outputs), f1_score/len(outputs), exact_score/len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9d509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
